{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification - per_question_model using Naive Bayes(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import Word\n",
    "from textblob import TextBlob\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.models import ActiveLearner\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('../dataset/mohler2_cleaned.csv',dtype = {'question_number':str})\n",
    "original_data = original_data.drop(labels='Unnamed: 0', axis=1)\n",
    "original_data = original_data.rename(columns={'question_number':'question_id','question_text':'question','answer_model':'ref_answer','answer_student':'student_answer','score_avg':'grade'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = original_data.copy()\n",
    "\n",
    "#converting to lower case\n",
    "df['ref_modified'] = df['ref_answer'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['student_modified'] = df['student_answer'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "#punctuation removal\n",
    "df['ref_modified'] = df['ref_modified'].str.replace('[^\\w\\s]','')\n",
    "df['student_modified'] = df['student_modified'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#stop word removal\n",
    "stop = stopwords.words('english')\n",
    "df['ref_modified'] = df['ref_modified'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['student_modified'] = df['student_modified'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "\n",
    "#lemmatisation\n",
    "df['ref_modified'] = df['ref_modified'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in word_tokenize(x)]))\n",
    "df['student_modified'] = df['student_modified'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words per question model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohandass/anaconda3/envs/maluuba/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question id: 1.1\n",
      "[0, 1, 4, 5]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.05 % is achieved on the unseen data\n",
      "question id: 1.2\n",
      "[0, 3, 5, 9, 23]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.44 % is achieved on the unseen data\n",
      "question id: 1.3\n",
      "[0, 1, 3, 5, 8]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.83 % is achieved on the unseen data\n",
      "question id: 1.4\n",
      "[0, 7, 12]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 1.5\n",
      "[0, 1, 2, 12]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.74 % is achieved on the unseen data\n",
      "question id: 1.6\n",
      "[0, 1, 2, 3, 18]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.33 % is achieved on the unseen data\n",
      "question id: 1.7\n",
      "[0, 1, 25]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.85 % is achieved on the unseen data\n",
      "question id: 2.1\n",
      "[0, 1, 2, 5]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.65 % is achieved on the unseen data\n",
      "question id: 2.2\n",
      "[0, 1, 2, 4]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.65 % is achieved on the unseen data\n",
      "question id: 2.3\n",
      "[0, 1, 2, 3]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.5 % is achieved on the unseen data\n",
      "question id: 2.4\n",
      "[0, 1, 3, 5, 10]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 2.5\n",
      "[0, 1, 3, 19]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.75 % is achieved on the unseen data\n",
      "question id: 2.6\n",
      "[0, 1, 2, 3]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.55 % is achieved on the unseen data\n",
      "question id: 2.7\n",
      "[0, 1, 3, 9, 15, 29]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.56 % is achieved on the unseen data\n",
      "question id: 3.1\n",
      "[0, 1, 2, 16]\n",
      "7\n",
      "By just labelling 10 % of total data accuracy of  0.95 % is achieved on the unseen data\n",
      "question id: 3.2\n",
      "[0, 1, 5, 7]\n",
      "7\n",
      "By just labelling 10 % of total data accuracy of  0.5 % is achieved on the unseen data\n",
      "question id: 3.3\n",
      "[0, 2, 3, 5, 17]\n",
      "7\n",
      "By just labelling 10 % of total data accuracy of  0.53 % is achieved on the unseen data\n",
      "question id: 3.4\n",
      "[0, 1, 5]\n",
      "7\n",
      "By just labelling 10 % of total data accuracy of  0.43 % is achieved on the unseen data\n",
      "question id: 3.5\n",
      "[0, 1, 12, 14]\n",
      "7\n",
      "By just labelling 10 % of total data accuracy of  0.8 % is achieved on the unseen data\n",
      "question id: 3.6\n",
      "[0, 1, 5, 30]\n",
      "7\n",
      "By just labelling 10 % of total data accuracy of  0.85 % is achieved on the unseen data\n",
      "question id: 3.7\n",
      "[0, 1, 6, 7, 12]\n",
      "7\n",
      "By just labelling 10 % of total data accuracy of  0.79 % is achieved on the unseen data\n",
      "question id: 4.1\n",
      "[0, 2, 3, 7]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.25 % is achieved on the unseen data\n",
      "question id: 4.2\n",
      "[0, 1, 2, 6]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.15 % is achieved on the unseen data\n",
      "question id: 4.3\n",
      "[0, 1, 12, 16]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.75 % is achieved on the unseen data\n",
      "question id: 4.4\n",
      "[0, 1, 7, 24]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.6 % is achieved on the unseen data\n",
      "question id: 4.5\n",
      "[0, 1, 2, 17, 24]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.32 % is achieved on the unseen data\n",
      "question id: 4.6\n",
      "[0, 2, 24]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 4.7\n",
      "[0, 1, 3, 11]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.9 % is achieved on the unseen data\n",
      "question id: 5.1\n",
      "[0, 1, 2, 4]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.56 % is achieved on the unseen data\n",
      "question id: 5.2\n",
      "[0, 1]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.8 % is achieved on the unseen data\n",
      "question id: 5.3\n",
      "[0, 2, 4, 5]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.56 % is achieved on the unseen data\n",
      "question id: 5.4\n",
      "[0, 3, 8]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.74 % is achieved on the unseen data\n",
      "question id: 6.1\n",
      "[0, 4]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.61 % is achieved on the unseen data\n",
      "question id: 6.2\n",
      "[0, 5, 8]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.94 % is achieved on the unseen data\n",
      "question id: 6.3\n",
      "[0, 5, 22]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.88 % is achieved on the unseen data\n",
      "question id: 6.4\n",
      "[0, 1, 5, 10, 25]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.87 % is achieved on the unseen data\n",
      "question id: 6.5\n",
      "[0, 2, 10, 11]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.5 % is achieved on the unseen data\n",
      "question id: 6.6\n",
      "[0, 1, 24]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 6.7\n",
      "[0, 5]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.89 % is achieved on the unseen data\n",
      "question id: 7.1\n",
      "[0, 11, 17]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 7.2\n",
      "[0, 3, 10]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.94 % is achieved on the unseen data\n",
      "question id: 7.3\n",
      "[0, 1, 6, 10]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.69 % is achieved on the unseen data\n",
      "question id: 7.4\n",
      "[0, 1, 3, 10, 14]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.4 % is achieved on the unseen data\n",
      "question id: 7.5\n",
      "[0, 1, 2, 8, 20]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.93 % is achieved on the unseen data\n",
      "question id: 7.6\n",
      "[0, 14, 24, 25]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 7.7\n",
      "[0, 1, 3, 16, 25]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.73 % is achieved on the unseen data\n",
      "question id: 8.1\n",
      "[0, 2, 4]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.94 % is achieved on the unseen data\n",
      "question id: 8.2\n",
      "[0]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 8.3\n",
      "[0, 2, 4, 6]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.76 % is achieved on the unseen data\n",
      "question id: 8.4\n",
      "[0, 1, 2, 6]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.65 % is achieved on the unseen data\n",
      "question id: 8.5\n",
      "[0, 3, 8, 21, 26]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.75 % is achieved on the unseen data\n",
      "question id: 8.6\n",
      "[0, 3, 4, 11]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.82 % is achieved on the unseen data\n",
      "question id: 8.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohandass/anaconda3/envs/maluuba/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 5, 9]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.24 % is achieved on the unseen data\n",
      "question id: 9.1\n",
      "[0, 1]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.95 % is achieved on the unseen data\n",
      "question id: 9.2\n",
      "[0, 26]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 9.3\n",
      "[0, 1, 3, 19]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.12 % is achieved on the unseen data\n",
      "question id: 9.4\n",
      "[0, 1, 4, 13]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.59 % is achieved on the unseen data\n",
      "question id: 9.5\n",
      "[0, 1, 9]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.56 % is achieved on the unseen data\n",
      "question id: 9.6\n",
      "[0, 4, 5]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 9.7\n",
      "[0, 1]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 10.1\n",
      "[0, 1, 5, 17]\n",
      "5\n",
      "By just labelling 10 % of total data accuracy of  0.6 % is achieved on the unseen data\n",
      "question id: 10.2\n",
      "[0, 2, 12, 23]\n",
      "5\n",
      "By just labelling 10 % of total data accuracy of  0.73 % is achieved on the unseen data\n",
      "question id: 10.3\n",
      "[0, 6, 7, 8]\n",
      "5\n",
      "By just labelling 10 % of total data accuracy of  0.93 % is achieved on the unseen data\n",
      "question id: 10.4\n",
      "[0, 1, 12]\n",
      "5\n",
      "By just labelling 10 % of total data accuracy of  0.75 % is achieved on the unseen data\n",
      "question id: 10.5\n",
      "[0, 5, 9]\n",
      "5\n",
      "By just labelling 10 % of total data accuracy of  0.75 % is achieved on the unseen data\n",
      "question id: 10.6\n",
      "[0, 1, 2, 3]\n",
      "5\n",
      "By just labelling 10 % of total data accuracy of  0.6 % is achieved on the unseen data\n",
      "question id: 10.7\n",
      "[0, 2, 6, 14, 23]\n",
      "5\n",
      "By just labelling 10 % of total data accuracy of  0.36 % is achieved on the unseen data\n",
      "question id: 11.1\n",
      "[0, 2, 3, 7]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.55 % is achieved on the unseen data\n",
      "question id: 11.2\n",
      "[0, 12, 14, 15]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.95 % is achieved on the unseen data\n",
      "question id: 11.3\n",
      "[0, 1, 2, 6, 7, 12]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.39 % is achieved on the unseen data\n",
      "question id: 11.4\n",
      "[0, 1, 3, 5]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.85 % is achieved on the unseen data\n",
      "question id: 11.5\n",
      "[0, 2, 3]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.9 % is achieved on the unseen data\n",
      "question id: 11.6\n",
      "[0, 1, 29]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 11.7\n",
      "[0, 1, 3, 5]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.35 % is achieved on the unseen data\n",
      "question id: 11.8\n",
      "[0, 1, 6, 8]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.75 % is achieved on the unseen data\n",
      "question id: 11.9\n",
      "[0, 1, 25]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.14 % is achieved on the unseen data\n",
      "question id: 11.10\n",
      "[0, 1]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.91 % is achieved on the unseen data\n",
      "question id: 12.1\n",
      "[0, 12, 27]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.95 % is achieved on the unseen data\n",
      "question id: 12.2\n",
      "[0, 1, 2, 4, 8]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.29 % is achieved on the unseen data\n",
      "question id: 12.3\n",
      "[0, 1, 6, 21]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.5 % is achieved on the unseen data\n",
      "question id: 12.4\n",
      "[0, 2, 3, 15]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.17 % is achieved on the unseen data\n",
      "question id: 12.5\n",
      "[0, 11]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 12.6\n",
      "[0, 2, 10]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.95 % is achieved on the unseen data\n",
      "question id: 12.7\n",
      "[0, 11]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  1.0 % is achieved on the unseen data\n",
      "question id: 12.8\n",
      "[0, 1, 2, 3, 22]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.53 % is achieved on the unseen data\n",
      "question id: 12.9\n",
      "[0, 4, 5, 19, 22]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.59 % is achieved on the unseen data\n",
      "question id: 12.10\n",
      "[0, 4, 8]\n",
      "6\n",
      "By just labelling 10 % of total data accuracy of  0.74 % is achieved on the unseen data\n"
     ]
    }
   ],
   "source": [
    "short_df = df[['question_id','student_answer','student_modified', 'grade','question']]\n",
    "short_df['grades_round']= short_df['grade'].apply(lambda x: round(x))\n",
    "ques_id_list = list(short_df['question_id'].unique())\n",
    "Accuracy_dict = {}\n",
    "accuracy_list = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "while  ques_id_list :\n",
    "    print(\"question id:\",ques_id_list[0])\n",
    "    # FOR ONE BY ONE QUESTION\n",
    "    ques_df = short_df[short_df['question_id'] == ques_id_list[0]]\n",
    "    ques_df.reset_index(drop = True,inplace=True)\n",
    "    \n",
    "\n",
    "    # counting unique words in every student's answer\n",
    "    # Tf-idf creation\n",
    "    Tf = TfidfVectorizer()\n",
    "    tfidf_vector = Tf.fit_transform(ques_df['student_modified'])\n",
    "    tfidf_vector = tfidf_vector.toarray()\n",
    "\n",
    "    X = tfidf_vector\n",
    "    Y = ques_df['grades_round'].values\n",
    "\n",
    "    #getting the seed index\n",
    "    classes = ques_df['grades_round'].unique()\n",
    "    seed_index = []\n",
    "    for i in classes:\n",
    "        seed_index.append(ques_df['grades_round'][ques_df['grades_round']==i].index[0])\n",
    "    print(seed_index)\n",
    "\n",
    "    act_data = ques_df.copy()\n",
    "#     accuracy_list = []\n",
    "\n",
    "    # initialising\n",
    "    train_idx = seed_index\n",
    "    X_train = X[train_idx]\n",
    "    y_train = Y[train_idx]\n",
    "\n",
    "    # generating the pool\n",
    "    X_pool = np.delete(X, train_idx, axis=0)\n",
    "    y_pool = np.delete(Y, train_idx)\n",
    "\n",
    "    act_data = act_data.drop(axis=0,index = train_idx)\n",
    "    act_data.reset_index(drop = True,inplace=True)\n",
    "\n",
    "\n",
    "    # initializing the active learner\n",
    "    # lr = LogisticRegression()\n",
    "    nb = MultinomialNB()\n",
    "    learner = ActiveLearner(\n",
    "    #     estimator = lr,\n",
    "        estimator = nb,\n",
    "    #     estimator = RandomForestClassifier(n_estimators=5),\n",
    "    #     estimator=KNeighborsClassifier(n_neighbors=3),\n",
    "        X_training=X_train, y_training=y_train\n",
    "    )\n",
    "\n",
    "    # pool-based sampling\n",
    "    n_queries = math.ceil(len(ques_df)/5.0)\n",
    "    print (n_queries)\n",
    "    for idx in range(n_queries):\n",
    "        query_idx, query_instance = learner.query(X_pool)\n",
    "#         print(\"Question number: \", ques_id_list[0])\n",
    "#         print(\"\\nQ: \", act_data.loc[int(query_idx),'question'])\n",
    "#         print(\"A: \",act_data.loc[int(query_idx),'student_answer'])\n",
    "#         print(\"Actual grade: \",y_pool[query_idx].reshape(1, ))\n",
    "#     #     print(learner.sigma_)\n",
    "#         print (\"Class probabilities: \",learner.predict_proba(X_pool[query_idx].reshape(1, -1)))\n",
    "#         human_label = int(input(\"\\nGive me a grade 0 or 1:\"))\n",
    "        learner.teach(\n",
    "            X=X_pool[query_idx].reshape(1, -1),\n",
    "            y=y_pool[query_idx].reshape(1, )\n",
    "        )\n",
    "\n",
    "        # remove queried instance from pool\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx)\n",
    "\n",
    "        act_data = act_data.drop(axis=0,index = query_idx)\n",
    "        act_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#         accuracy_list.append(learner.score(X,Y))\n",
    "#         print('Accuracy after query no. %d: %f' % (idx+1, learner.score(X, Y)))\n",
    "    accuracy_list.append(learner.score(X_pool, y_pool))\n",
    "    Accuracy_dict[ques_id_list[0]] = accuracy_list\n",
    "    print(\"By just labelling 10 % of total data accuracy of \", round(learner.score(X_pool, y_pool),2), \"% is achieved on the unseen data\"  )\n",
    "    ques_id_list.pop(0)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in list(short_df['question_id'].unique()):\n",
    "plt.figure()\n",
    "plt.bar(np.linspace(0,len(accuracy_list)-1,len(accuracy_list)), accuracy_list)\n",
    "plt.title(\"Accuracy for each quesstion\")\n",
    "plt.xlabel(\"Query number\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlgeval",
   "language": "python",
   "name": "maluuba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
