{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification Mohler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import Word\n",
    "from textblob import TextBlob\n",
    "from nltk import PorterStemmer\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.models import ActiveLearner\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../dataset/sultan_features.pkl\")\n",
    "df = df.fillna(0)\n",
    "df['cos_similarity'] = df['cos_similarity'].apply(lambda x: max(x,0))\n",
    "df['cos_similarity_demo'] = df['cos_similarity_demo'].apply(lambda x: max(x,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Active_learner():\n",
    "    def __init__(self,X,Y,model,data, percentage):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.short_df = data.copy()\n",
    "        self.percent = percentage\n",
    "        self.model = model\n",
    "        \n",
    "    def learn(self):       \n",
    "        # seeding\n",
    "        classes = self.short_df['grades_round'].unique()\n",
    "        seed_index = []\n",
    "        for i in classes:\n",
    "            seed_index.append(self.short_df['grades_round'][self.short_df['grades_round']==i].index[0])\n",
    "        seed_index\n",
    "\n",
    "        act_data = self.short_df.copy()\n",
    "        accuracy_list = []\n",
    "\n",
    "        # initialising\n",
    "        train_idx = seed_index\n",
    "        X_train = self.X[train_idx]\n",
    "        y_train = self.Y[train_idx]\n",
    "\n",
    "        # generating the pool\n",
    "        X_pool = np.delete(X, train_idx, axis=0)\n",
    "        y_pool = np.delete(Y, train_idx)\n",
    "\n",
    "        act_data = act_data.drop(axis=0,index = train_idx)\n",
    "        act_data.reset_index(drop = True,inplace=True)\n",
    "\n",
    "\n",
    "        # initializing the active learner\n",
    "\n",
    "        learner = ActiveLearner(\n",
    "            estimator = self.model,\n",
    "            X_training = X_train, y_training=y_train\n",
    "        )\n",
    "\n",
    "        # pool-based sampling\n",
    "        n_queries = int(len(X)/(100/self.percent))\n",
    "        for idx in range(n_queries):\n",
    "            query_idx, query_instance = learner.query(X_pool)   \n",
    "            learner.teach(\n",
    "                X=X_pool[query_idx].reshape(1, -1),\n",
    "                y=y_pool[query_idx].reshape(1, )\n",
    "            )\n",
    "\n",
    "            # remove queried instance from pool\n",
    "            X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "            y_pool = np.delete(y_pool, query_idx)\n",
    "\n",
    "            act_data = act_data.drop(axis=0,index = query_idx)\n",
    "            act_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            accuracy_list.append(learner.score(X_pool,y_pool))\n",
    "        #     print('Accuracy after query no. %d: %f' % (idx+1, learner.score(X_pool, y_pool)))\n",
    "        print(\"By just labelling \",round(n_queries*100.0/len(X),2),\"% of total data accuracy of \", round(learner.score(X_pool, y_pool),3), \" % is achieved on the unseen data\" )\n",
    "        model_pred = model.predict(X_pool)\n",
    "        model_f1 = f1_score(y_pool,model_pred,average='weighted')\n",
    "        return accuracy_list,model_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sultan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating inputs and labels for sultan\n",
    "X = df[['length_ratio','aligned_score','aligned_score_demo','cos_similarity','cos_similarity_demo']]\n",
    "X = np.array(X)\n",
    "Y = df['grades_round'].values\n",
    "\n",
    "models = [LogisticRegression(),MultinomialNB(),RandomForestClassifier(),SVC(kernel='linear' , probability=True),SVC(probability=True)]\n",
    "dict_accuracy_al ={}\n",
    "f1_score_list = []\n",
    "for i,model in enumerate(models):\n",
    "    ac = Active_learner(X,Y,model,df, 30)\n",
    "    accuracy_list,f1 = ac.learn()\n",
    "    dict_accuracy_al[i] = accuracy_list\n",
    "    f1_score_list.append(f1_score)\n",
    "    \n",
    "dict_accuracy_sl= []    \n",
    "#Logistic regression\n",
    "lr_accuracy_list = []\n",
    "lr_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    lr_accuracy = lr.score(X_test, Y_test)\n",
    "    lr_pred = lr.predict(X_test)\n",
    "    lr_f1 = f1_score(Y_test,lr_pred,average='weighted')\n",
    "    lr_accuracy_list.append(lr_accuracy)\n",
    "    lr_f1_list.append(lr_f1)\n",
    "lr_accuracy_mean = np.mean(lr_accuracy_list)\n",
    "lr_f1_mean = np.mean(lr_f1_list)\n",
    "dict_accuracy_sl.append(lr_accuracy_mean)\n",
    "\n",
    "# naive bayes classfier    \n",
    "nb_accuracy_list = []\n",
    "nb_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train, Y_train)\n",
    "    nb_accuracy = nb.score(X_test, Y_test)\n",
    "    nb_pred = nb.predict(X_test)\n",
    "    nb_f1 = f1_score(Y_test,nb_pred,average='weighted')\n",
    "    nb_accuracy_list.append(nb_accuracy)\n",
    "    nb_f1_list.append(nb_f1)\n",
    "nb_accuracy_mean = np.mean(nb_accuracy_list)\n",
    "nb_f1_mean = np.mean(nb_f1_list)\n",
    "dict_accuracy_sl.append(nb_accuracy_mean)\n",
    "\n",
    "\n",
    "\n",
    "# randomforest classfier    \n",
    "rf_accuracy_list = []\n",
    "rf_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, Y_train)\n",
    "    rf_accuracy = rf.score(X_test, Y_test)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    rf_f1 = f1_score(Y_test,rf_pred,average='weighted')\n",
    "    rf_accuracy_list.append(rf_accuracy)\n",
    "    rf_f1_list.append(rf_f1)\n",
    "rf_accuracy_mean = np.mean(rf_accuracy_list)\n",
    "rf_f1_mean = np.mean(rf_f1_list)\n",
    "dict_accuracy_sl.append(rf_accuracy_mean)\n",
    "\n",
    "\n",
    "\n",
    "# Linear SVC classfier    \n",
    "lsvc_accuracy_list = []\n",
    "lsvc_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    lsvc = SVC(kernel='linear',probability=True)\n",
    "    lsvc.fit(X_train, Y_train)\n",
    "    lsvc_accuracy = lsvc.score(X_test, Y_test)\n",
    "    lsvc_pred = lsvc.predict(X_test)\n",
    "    lsvc_f1 = f1_score(Y_test,lsvc_pred,average='weighted')\n",
    "    lsvc_accuracy_list.append(lsvc_accuracy)\n",
    "    lsvc_f1_list.append(lsvc_f1)\n",
    "lsvc_accuracy_mean = np.mean(lsvc_accuracy_list)\n",
    "lsvc_f1_mean = np.mean(lsvc_f1_list)\n",
    "dict_accuracy_sl.append(lsvc_accuracy_mean)\n",
    "\n",
    "\n",
    "# RBF_SVC   \n",
    "rsvc_accuracy_list = []\n",
    "rsvc_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    rsvc = SVC(probability=True)\n",
    "    rsvc.fit(X_train, Y_train)\n",
    "    rsvc_accuracy = rsvc.score(X_test, Y_test)\n",
    "    rsvc_pred = rsvc.predict(X_test)\n",
    "    rsvc_f1 = f1_score(Y_test,rsvc_pred,average='weighted')\n",
    "    rsvc_accuracy_list.append(rsvc_accuracy)\n",
    "    rsvc_f1_list.append(rsvc_f1)\n",
    "rsvc_accuracy_mean = np.mean(rsvc_accuracy_list)\n",
    "rsvc_f1_mean = np.mean(rsvc_f1_list)\n",
    "dict_accuracy_sl.append(rsvc_accuracy_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,20))\n",
    "\n",
    "for i in range(0,5):\n",
    "    ax = fig.add_subplot(3,2,i+1)\n",
    "    ax.plot(np.linspace(0,len(dict_accuracy_al[0])-1, len(dict_accuracy_al[0]) ), \\\n",
    "            [dict_accuracy_sl[i] for _ in range(len(dict_accuracy_al[0]))])\n",
    "    ax.plot(dict_accuracy_al[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By just labelling  9.99 % of total data accuracy of  0.5  % is achieved on the unseen data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohandass/anaconda3/envs/maluuba/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By just labelling  9.99 % of total data accuracy of  0.531  % is achieved on the unseen data\n"
     ]
    }
   ],
   "source": [
    "#creating inputs and labels for BOW\n",
    "CV = CountVectorizer()\n",
    "student_answer_count_vector = CV.fit_transform(df['student_modified'])\n",
    "student_answer_count_vector = student_answer_count_vector.toarray()\n",
    "\n",
    "X = student_answer_count_vector\n",
    "Y = df['grades_round'].values\n",
    "\n",
    "models = [LogisticRegression(),MultinomialNB(),RandomForestClassifier(),SVC(kernel='linear' , probability=True),SVC(probability=True)]\n",
    "dict_accuracy_al ={}\n",
    "f1_score_list = []\n",
    "for i,model in enumerate(models):\n",
    "    ac = Active_learner(X,Y,model,df, 10)\n",
    "    accuracy_list,f1 = ac.learn()\n",
    "    dict_accuracy_al[i] = accuracy_list\n",
    "    f1_score_list.append(f1_score)\n",
    "    \n",
    "dict_accuracy_sl= []    \n",
    "#Logistic regression\n",
    "lr_accuracy_list = []\n",
    "lr_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    lr_accuracy = lr.score(X_test, Y_test)\n",
    "    lr_pred = lr.predict(X_test)\n",
    "    lr_f1 = f1_score(Y_test,lr_pred)\n",
    "    lr_accuracy_list.append(lr_accuracy)\n",
    "    lr_f1_list.append(lr_f1)\n",
    "lr_accuracy_mean = np.mean(lr_accuracy_list)\n",
    "lr_f1_mean = np.mean(lr_f1_list)\n",
    "dict_accuracy_sl.append(lr_accuracy_mean)\n",
    "\n",
    "# naive bayes classfier    \n",
    "nb_accuracy_list = []\n",
    "nb_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train, Y_train)\n",
    "    nb_accuracy = nb.score(X_test, Y_test)\n",
    "    nb_pred = nb.predict(X_test)\n",
    "    nb_f1 = f1_score(Y_test,nb_pred)\n",
    "    nb_accuracy_list.append(nb_accuracy)\n",
    "    nb_f1_list.append(nb_f1)\n",
    "nb_accuracy_mean = np.mean(nb_accuracy_list)\n",
    "nb_f1_mean = np.mean(nb_f1_list)\n",
    "dict_accuracy_sl.append(nb_accuracy_mean)\n",
    "\n",
    "\n",
    "\n",
    "# randomforest classfier    \n",
    "rf_accuracy_list = []\n",
    "rf_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, Y_train)\n",
    "    rf_accuracy = rf.score(X_test, Y_test)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    rf_f1 = f1_score(Y_test,rf_pred)\n",
    "    rf_accuracy_list.append(rf_accuracy)\n",
    "    rf_f1_list.append(rf_f1)\n",
    "rf_accuracy_mean = np.mean(rf_accuracy_list)\n",
    "rf_f1_mean = np.mean(rf_f1_list)\n",
    "dict_accuracy_sl.append(rf_accuracy_mean)\n",
    "\n",
    "\n",
    "\n",
    "# Linear SVC classfier    \n",
    "lsvc_accuracy_list = []\n",
    "lsvc_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    lsvc = SVC(kernel='linear',probability=True)\n",
    "    lsvc.fit(X_train, Y_train)\n",
    "    lsvc_accuracy = lsvc.score(X_test, Y_test)\n",
    "    lsvc_pred = lsvc.predict(X_test)\n",
    "    lsvc_f1 = f1_score(Y_test,lsvc_pred)\n",
    "    lsvc_accuracy_list.append(lsvc_accuracy)\n",
    "    lsvc_f1_list.append(lsvc_f1)\n",
    "lsvc_accuracy_mean = np.mean(lsvc_accuracy_list)\n",
    "lsvc_f1_mean = np.mean(lsvc_f1_list)\n",
    "dict_accuracy_sl.append(lsvc_accuracy_mean)\n",
    "\n",
    "\n",
    "# RBF_SVC   \n",
    "rsvc_accuracy_list = []\n",
    "rsvc_f1_list = []\n",
    "for _ in range(1):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    rsvc = SVC(probability=True)\n",
    "    rsvc.fit(X_train, Y_train)\n",
    "    rsvc_accuracy = rsvc.score(X_test, Y_test)\n",
    "    rsvc_pred = rsvc.predict(X_test)\n",
    "    rsvc_f1 = f1_score(Y_test,rsvc_pred)\n",
    "    rsvc_accuracy_list.append(rsvc_accuracy)\n",
    "    rsvc_f1_list.append(rsvc_f1)\n",
    "rsvc_accuracy_mean = np.mean(rsvc_accuracy_list)\n",
    "rsvc_f1_mean = np.mean(rsvc_f1_list)\n",
    "dict_accuracy_sl.append(rsvc_accuracy_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,20))\n",
    "\n",
    "for i in range(0,5):\n",
    "    ax = fig.add_subplot(3,2,i+1)\n",
    "    ax.plot(np.linspace(0,len(dict_accuracy_al[0])-1, len(dict_accuracy_al[0]) ), \\\n",
    "            [dict_accuracy_sl[i] for _ in range(len(dict_accuracy_al[0]))])\n",
    "    ax.plot(dict_accuracy_al[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-IDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating inputs and labels for TFidf\n",
    "Tf = TfidfVectorizer()\n",
    "student_answer_count_vector = TF.fit_transform(df['student_modified'])\n",
    "student_answer_count_vector = student_answer_count_vector.toarray()\n",
    "\n",
    "X = student_answer_count_vector\n",
    "Y = short_df['status'].values\n",
    "\n",
    "\n",
    "models = [LogisticRegression(),MultinomialNB(),RandomForestClassifier(),SVC(kernel='linear' , probability=True),SVC(probability=True)]\n",
    "dict_accuracy_al ={}\n",
    "f1_score_list = []\n",
    "for i,model in enumerate(models):\n",
    "    ac = Active_learner(X,Y,model,df, 10)\n",
    "    accuracy_list,f1 = ac.learn()\n",
    "    dict_accuracy_al[i] = accuracy_list\n",
    "    f1_score_list.append(f1_score)\n",
    "    \n",
    "dict_accuracy_sl= []    \n",
    "#Logistic regression\n",
    "lr_accuracy_list = []\n",
    "lr_f1_list = []\n",
    "for _ in range(100):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    lr_accuracy = lr.score(X_test, Y_test)\n",
    "    lr_pred = lr.predict(X_test)\n",
    "    lr_f1 = f1_score(Y_test,lr_pred)\n",
    "    lr_accuracy_list.append(lr_accuracy)\n",
    "    lr_f1_list.append(lr_f1)\n",
    "lr_accuracy_mean = np.mean(lr_accuracy_list)\n",
    "lr_f1_mean = np.mean(lr_f1_list)\n",
    "dict_accuracy_sl.append(lr_accuracy_mean)\n",
    "\n",
    "# naive bayes classfier    \n",
    "nb_accuracy_list = []\n",
    "nb_f1_list = []\n",
    "for _ in range(100):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train, Y_train)\n",
    "    nb_accuracy = nb.score(X_test, Y_test)\n",
    "    nb_pred = nb.predict(X_test)\n",
    "    nb_f1 = f1_score(Y_test,nb_pred)\n",
    "    nb_accuracy_list.append(nb_accuracy)\n",
    "    nb_f1_list.append(nb_f1)\n",
    "nb_accuracy_mean = np.mean(nb_accuracy_list)\n",
    "nb_f1_mean = np.mean(nb_f1_list)\n",
    "dict_accuracy_sl.append(nb_accuracy_mean)\n",
    "\n",
    "\n",
    "\n",
    "# randomforest classfier    \n",
    "rf_accuracy_list = []\n",
    "rf_f1_list = []\n",
    "for _ in range(100):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, Y_train)\n",
    "    rf_accuracy = rf.score(X_test, Y_test)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    rf_f1 = f1_score(Y_test,rf_pred)\n",
    "    rf_accuracy_list.append(rf_accuracy)\n",
    "    rf_f1_list.append(rf_f1)\n",
    "rf_accuracy_mean = np.mean(rf_accuracy_list)\n",
    "rf_f1_mean = np.mean(rf_f1_list)\n",
    "dict_accuracy_sl.append(rf_accuracy_mean)\n",
    "\n",
    "\n",
    "\n",
    "# Linear SVC classfier    \n",
    "lsvc_accuracy_list = []\n",
    "lsvc_f1_list = []\n",
    "for _ in range(100):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    lsvc = SVC(kernel='linear',probability=True)\n",
    "    lsvc.fit(X_train, Y_train)\n",
    "    lsvc_accuracy = lsvc.score(X_test, Y_test)\n",
    "    lsvc_pred = lsvc.predict(X_test)\n",
    "    lsvc_f1 = f1_score(Y_test,lsvc_pred)\n",
    "    lsvc_accuracy_list.append(lsvc_accuracy)\n",
    "    lsvc_f1_list.append(lsvc_f1)\n",
    "lsvc_accuracy_mean = np.mean(lsvc_accuracy_list)\n",
    "lsvc_f1_mean = np.mean(lsvc_f1_list)\n",
    "dict_accuracy_sl.append(lsvc_accuracy_mean)\n",
    "\n",
    "\n",
    "# RBF_SVC   \n",
    "rsvc_accuracy_list = []\n",
    "rsvc_f1_list = []\n",
    "for _ in range(100):\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "    rsvc = SVC(probability=True)\n",
    "    rsvc.fit(X_train, Y_train)\n",
    "    rsvc_accuracy = rsvc.score(X_test, Y_test)\n",
    "    rsvc_pred = rsvc.predict(X_test)\n",
    "    rsvc_f1 = f1_score(Y_test,rsvc_pred)\n",
    "    rsvc_accuracy_list.append(rsvc_accuracy)\n",
    "    rsvc_f1_list.append(rsvc_f1)\n",
    "rsvc_accuracy_mean = np.mean(rsvc_accuracy_list)\n",
    "rsvc_f1_mean = np.mean(rsvc_f1_list)\n",
    "dict_accuracy_sl.append(rsvc_accuracy_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,20))\n",
    "\n",
    "for i in range(0,5):\n",
    "    ax = fig.add_subplot(3,2,i+1)\n",
    "    ax.plot(np.linspace(0,len(dict_accuracy_al[0])-1, len(dict_accuracy_al[0]) ), \\\n",
    "            [dict_accuracy_sl[i] for _ in range(len(dict_accuracy_al[0]))])\n",
    "    ax.plot(dict_accuracy_al[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlgeval",
   "language": "python",
   "name": "maluuba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
