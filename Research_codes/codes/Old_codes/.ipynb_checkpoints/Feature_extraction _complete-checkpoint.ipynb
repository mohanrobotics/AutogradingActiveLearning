{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from scipy import spatial\n",
    "from textblob import Word\n",
    "from textblob import TextBlob\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "import gensim\n",
    "# model = gensim.models.KeyedVectors.load_word2vec_format('~/downloads/rnd/data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "from scipy import spatial\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embed(word):\n",
    "    try:\n",
    "        vec = model[word]\n",
    "        vec = vec.reshape(1,vec.shape[0])\n",
    "    except:\n",
    "    vec = np.ones((1, 300))*0.01\n",
    "        #this is hardcoded\n",
    "    return vec\n",
    "\n",
    "def model_embed_demoted_ref(data):\n",
    "    sentence  = data ['ref_demoted']\n",
    "    sentence_array = [word_embed(word) for word in sentence.split()]\n",
    "    return np.sum(sentence_array,axis=0)\n",
    "\n",
    "def model_embed_demoted_stud(data):\n",
    "    sentence  = data ['student_demoted']\n",
    "    sentence_array = [word_embed(word) for word in sentence.split()]\n",
    "    return np.sum(sentence_array,axis=0)\n",
    "\n",
    "def model_embed_ref(data):\n",
    "    sentence  = data ['ref_modified']\n",
    "    sentence_array = [word_embed(word) for word in sentence.split()]\n",
    "    return np.sum(sentence_array,axis=0)\n",
    "\n",
    "def model_embed_stud(data):\n",
    "    sentence  = data ['student_modified']\n",
    "    sentence_array = [word_embed(word) for word in sentence.split()]\n",
    "    return np.sum(sentence_array,axis=0)\n",
    "\n",
    "## question Demoting functions\n",
    "\n",
    "def student_demoting(data):\n",
    "    return \" \".join(x for x in data['student_modified'].split() if x not in data['qn_modified'])\n",
    "\n",
    "def ref_demoting(data):\n",
    "    return \" \".join(x for x in data['ref_modified'].split() if x not in data['qn_modified'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(\"./nn_final_wt_ref.pkl\")\n",
    "\n",
    "\n",
    "#converting to lower case\n",
    "df['qn_modified'] = df['question'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['ref_modified'] = df['ref_answer'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['student_modified'] = df['student_answer'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "#punctuation removal\n",
    "df['qn_modified'] = df['qn_modified'].str.replace('[^\\w\\s]','')\n",
    "df['ref_modified'] = df['ref_modified'].str.replace('[^\\w\\s]','')\n",
    "df['student_modified'] = df['student_modified'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#stop word removal\n",
    "stop = stopwords.words('english')\n",
    "df['qn_modified'] = df['qn_modified'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['ref_modified'] = df['ref_modified'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['student_modified'] = df['student_modified'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "#lemmatisation\n",
    "df['qn_modified'] = df['qn_modified'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in word_tokenize(x)]))\n",
    "df['ref_modified'] = df['ref_modified'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in word_tokenize(x)]))\n",
    "df['student_modified'] = df['student_modified'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in word_tokenize(x)]))\n",
    "\n",
    "#question demoting\n",
    "df['student_demoted'] = df.apply(student_demoting,axis=1)\n",
    "df['ref_demoted'] = df.apply(ref_demoting,axis=1)\n",
    "\n",
    "#length ratio\n",
    "df['length_ratio'] = df['student_modified'].apply(lambda x: len(x)) / df['ref_modified'].apply(lambda x: len(x))\n",
    "\n",
    "#getting the word embeddings\n",
    "df['embed_ref'] = df.apply(model_embed_ref,axis = 1)\n",
    "df['embed_stud'] = df.apply(model_embed_stud,axis = 1)\n",
    "\n",
    "df['embed_ref_demoted'] = df.apply(model_embed_demoted_ref,axis = 1)\n",
    "df['embed_stud_demoted'] = df.apply(model_embed_demoted_stud,axis = 1)\n",
    "\n",
    "\n",
    "# df.to_pickle('nn_final_wt_ref_embed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##numeric removal\n",
    "df['ref_modified'] = df['ref_modified'].apply(lambda x: \" \".join(word for word in x.split() if not word.isdigit()))\n",
    "df['student_modified'] = df['student_modified'].apply(lambda x: \" \".join(word for word in x.split() if not word.isdigit()))\n",
    "\n",
    "\n",
    "##numeric removal\n",
    "df['ref_demoted'] = df['ref_demoted'].apply(lambda x: \" \".join(word for word in x.split() if not word.isdigit()))\n",
    "df['student_demoted'] = df['student_demoted'].apply(lambda x: \" \".join(word for word in x.split() if not word.isdigit()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ramesh code for word aligner.\n",
    "Put this under\n",
    "~/Semantic-Textual-Similarity/monolingualWordAligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from wordAligner import *\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#sentence1 = \"Four people died in accident. Well, United Arab Emirates is one of powerful country\"\n",
    "#sentence2 = \"Seven men are dead due to collisions.\"\n",
    "\n",
    "\n",
    "\n",
    "#print \"sentence1 = \", sentence1\n",
    "#print \"sentence2 = \", sentence2\n",
    "\n",
    "\n",
    "def align_sentence_demoted(data):\n",
    "        sentence1 = str(data['ref_demoted'])\n",
    "        sentence2 = str(data['student_demoted'])\n",
    "        if len(sentence1) == 0 or len(sentence2)==0 :\n",
    "                return []\n",
    "        else:\n",
    "             \t#print type(sentence1),sentence1\n",
    "                processing = Aligner(flag)\n",
    "                aligned = processing.align_sentences(sentence1,sentence2)\n",
    "                return aligned\n",
    "\n",
    "def align_sentence(data):\n",
    "        sentence1 = str(data['ref_modified'])\n",
    "        sentence2 = str(data['student_modified'])\n",
    "        if len(sentence1) == 0 or len(sentence2)==0 :\n",
    "                return []\n",
    "        else:\n",
    "             \t#print type(sentence1),sentence1\n",
    "                processing = Aligner(flag)\n",
    "                aligned = processing.align_sentences(sentence1,sentence2)\n",
    "                return aligned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the cos similarity and alignement ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity_demo(data):\n",
    "    return 1 - spatial.distance.cosine(data['embed_ref_demoted'],data['embed_stud_demoted'])\n",
    "\n",
    "def cos_similarity(data):\n",
    "    return 1 - spatial.distance.cosine(data['embed_ref'],data['embed_stud'])\n",
    "\n",
    "def align_ratio(data):\n",
    "    return (2*len(data['aligned'])) / (len(data['ref_answer'].split()) + len(data['student_answer'].split()))\n",
    "\n",
    "def align_ratio_demo(data):\n",
    "    return (2*len(data['aligned_demoted'])) / 0.1+(len(data['ref_demoted'].split()) + len(data['student_demoted'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cos_similarity'] = df.apply(cos_similarity, axis=1)\n",
    "#df['cos_similarity_demoted'] = df.apply(cos_similarity_demo, axis=1)\n",
    "\n",
    "#getting aligned scores\n",
    "#df['aligned_score'] = df.apply(align_ratio, axis=1)\n",
    "#df['aligned_score_demo'] = df.apply(align_ratio_demo, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling zeros and NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-1, inplace=True)\n",
    "mms = MinMaxScaler()\n",
    "df[['length_ratio', 'align_ratio', 'align_ratio_demoted', 'cos_similarity', 'cos_similarity_demoted']] = \\\n",
    "mms.fit_transform(df[['length_ratio', 'align_ratio', 'align_ratio_demoted','cos_similarity', 'cos_similarity_demoted']])\n",
    "\n",
    "\n",
    "print (np.sum(df['cos_similarity']<0))\n",
    "print (np.sum(df['cos_similarity'].isnull()))\n",
    "print (np.sum(df['cos_similarity_demo']<0))\n",
    "print (np.sum(df['cos_similarity_demo'].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modifying the preprocessing.(numeric removal ignoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to lower case\n",
    "df['qn_modified'] = df['question'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['ref_modified'] = df['ref_answer'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['student_modified'] = df['student_answer'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "#punctuation removal\n",
    "df['qn_modified'] = df['qn_modified'].str.replace('[^\\w\\s]','')\n",
    "df['ref_modified'] = df['ref_modified'].str.replace('[^\\w\\s]','')\n",
    "df['student_modified'] = df['student_modified'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#stop word removal\n",
    "stop = stopwords.words('english')\n",
    "df['qn_modified'] = df['qn_modified'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['ref_modified'] = df['ref_modified'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['student_modified'] = df['student_modified'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "#lemmatisation\n",
    "df['qn_modified'] = df['qn_modified'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in word_tokenize(x)]))\n",
    "df['ref_modified'] = df['ref_modified'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in word_tokenize(x)]))\n",
    "df['student_modified'] = df['student_modified'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2442"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../../dataset/final_dataset/mohler_final.pkl\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#punctuation removal\n",
    "df['qn_modified'] = df['qn_modified'].str.replace('[^\\w\\s]','')\n",
    "df['ref_modified'] = df['ref_modified'].str.replace('[^\\w\\s]','')\n",
    "df['student_modified'] = df['student_modified'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ref_modified'] = df['ref_modified'].str.replace('_','')\n",
    "df['student_modified'] = df['student_modified'].str.replace('_','')\n",
    "df['student_demoted'] = df['student_demoted'].str.replace('_','')\n",
    "df['ref_demoted'] = df['ref_demoted'].str.replace('_','')\n",
    "df['student_answer'] = df['student_answer'].str.replace('_','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohandass/anaconda3/envs/maluuba/lib/python3.6/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../../../../../nn_final_wt_ref_embed.pkl\")\n",
    "def cos_similarity_demo(data):\n",
    "    return 1 - spatial.distance.cosine(data['embed_ref_demoted'],data['embed_stud_demoted'])\n",
    "\n",
    "def cos_similarity(data):\n",
    "    return 1 - spatial.distance.cosine(data['embed_ref'],data['embed_stud'])\n",
    "\n",
    "def align_ratio(data):\n",
    "    return (2*len(data['aligned'])) / (len(data['ref_answer'].split()) + len(data['student_answer'].split()))\n",
    "\n",
    "def align_ratio_demo(data):\n",
    "    return (2*len(data['aligned_demoted'])) / (1e-5+(len(data['ref_demoted'].split()) + len(data['student_demoted'].split())))\n",
    "\n",
    "\n",
    "df['cos_similarity'] = df.apply(cos_similarity, axis=1)\n",
    "df['cos_similarity_demo'] = df.apply(cos_similarity_demo, axis=1)\n",
    "\n",
    "#getting aligned scores\n",
    "df['aligned_score'] = df.apply(align_ratio, axis=1)\n",
    "df['aligned_score_demo'] = df.apply(align_ratio_demo, axis=1)\n",
    "df.fillna(0, inplace=True)\n",
    "mms = MinMaxScaler()\n",
    "df[['length_ratio', 'aligned_score', 'aligned_score_demo', 'cos_similarity', 'cos_similarity_demo']] = \\\n",
    "mms.fit_transform(df[['length_ratio', 'aligned_score', 'aligned_score_demo','cos_similarity', 'cos_similarity_demo']])\n",
    "\n",
    "print (np.sum(df['cos_similarity']<0))\n",
    "print (np.sum(df['cos_similarity'].isnull()))\n",
    "print (np.sum(df['cos_similarity_demo']<0))\n",
    "print (np.sum(df['cos_similarity_demo'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../../dataset/final_dataset/nn_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>grades_round</th>\n",
       "      <th>student_modified</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>qn_modified</th>\n",
       "      <th>ref_modified</th>\n",
       "      <th>student_demoted</th>\n",
       "      <th>ref_demoted</th>\n",
       "      <th>length_ratio</th>\n",
       "      <th>embed_ref</th>\n",
       "      <th>embed_stud</th>\n",
       "      <th>embed_ref_demoted</th>\n",
       "      <th>embed_stud_demoted</th>\n",
       "      <th>aligned</th>\n",
       "      <th>aligned_demoted</th>\n",
       "      <th>cos_similarity</th>\n",
       "      <th>cos_similarity_demo</th>\n",
       "      <th>aligned_score</th>\n",
       "      <th>aligned_score_demo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Give a definition for the term \"artificial ne...</td>\n",
       "      <td>An artificial neural network is a massively pa...</td>\n",
       "      <td>2</td>\n",
       "      <td>artificial neural network massively parallel d...</td>\n",
       "      <td>A neural network is a massively parallel distr...</td>\n",
       "      <td>give definition term artificial neural network...</td>\n",
       "      <td>neural network massively parallel distributed ...</td>\n",
       "      <td>massively parallel distributed processor simpl...</td>\n",
       "      <td>massively parallel distributed processor made ...</td>\n",
       "      <td>0.251889</td>\n",
       "      <td>[[1.5640869, 1.7378178, -0.1736145, 2.0961304,...</td>\n",
       "      <td>[[2.2006836, 0.86382484, 0.27182007, 2.5562744...</td>\n",
       "      <td>[[1.6300049, 1.5985355, -0.1282959, 1.0488892,...</td>\n",
       "      <td>[[2.0412598, 0.49321938, 0.10058594, 1.2648926...</td>\n",
       "      <td>[[neural, neural], [network, network], [massiv...</td>\n",
       "      <td>[[simple, simple], [processing, processing], [...</td>\n",
       "      <td>0.947867</td>\n",
       "      <td>0.933466</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.950888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Give a definition for the term \"artificial ne...</td>\n",
       "      <td>Artificial neural network consists of: . Large...</td>\n",
       "      <td>2</td>\n",
       "      <td>artificial neural network consists largely par...</td>\n",
       "      <td>A neural network is a massively parallel distr...</td>\n",
       "      <td>give definition term artificial neural network...</td>\n",
       "      <td>neural network massively parallel distributed ...</td>\n",
       "      <td>consists largely parallel distributed processo...</td>\n",
       "      <td>massively parallel distributed processor made ...</td>\n",
       "      <td>0.232759</td>\n",
       "      <td>[[1.5640869, 1.7378178, -0.1736145, 2.0961304,...</td>\n",
       "      <td>[[1.335439453125, 1.0990445709228516, 0.529989...</td>\n",
       "      <td>[[1.6300049, 1.5985355, -0.1282959, 1.0488892,...</td>\n",
       "      <td>[[1.1956689453125, 0.7539517974853516, 0.13561...</td>\n",
       "      <td>[[knowledge, knowledge], [parallel, parallel],...</td>\n",
       "      <td>[[knowledge, knowledge], [knowledge, knowledge...</td>\n",
       "      <td>0.964398</td>\n",
       "      <td>0.951182</td>\n",
       "      <td>0.883259</td>\n",
       "      <td>0.818713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Give a definition for the term \"artificial ne...</td>\n",
       "      <td>An artificial neural network is a massive dist...</td>\n",
       "      <td>1</td>\n",
       "      <td>artificial neural network massive distributed ...</td>\n",
       "      <td>A neural network is a massively parallel distr...</td>\n",
       "      <td>give definition term artificial neural network...</td>\n",
       "      <td>neural network massively parallel distributed ...</td>\n",
       "      <td>massive distributed processor consists several...</td>\n",
       "      <td>massively parallel distributed processor made ...</td>\n",
       "      <td>0.102828</td>\n",
       "      <td>[[1.5640869, 1.7378178, -0.1736145, 2.0961304,...</td>\n",
       "      <td>[[0.41577148, -0.37836266, 0.22351074, 0.95300...</td>\n",
       "      <td>[[1.6300049, 1.5985355, -0.1282959, 1.0488892,...</td>\n",
       "      <td>[[0.38427734, -0.48944664, 0.17224121, 0.55065...</td>\n",
       "      <td>[[knowledge, knowledge], [neural, neural], [ne...</td>\n",
       "      <td>[[knowledge, knowledge], [distributed, distrib...</td>\n",
       "      <td>0.854767</td>\n",
       "      <td>0.775333</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.465632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Give a definition for the term \"artificial ne...</td>\n",
       "      <td>An ANN is a layered graphical model containing...</td>\n",
       "      <td>2</td>\n",
       "      <td>ann layered graphical model containing neuron ...</td>\n",
       "      <td>A neural network is a massively parallel distr...</td>\n",
       "      <td>give definition term artificial neural network...</td>\n",
       "      <td>neural network massively parallel distributed ...</td>\n",
       "      <td>ann layered graphical model containing neuron ...</td>\n",
       "      <td>massively parallel distributed processor made ...</td>\n",
       "      <td>0.327616</td>\n",
       "      <td>[[1.5640869, 1.7378178, -0.1736145, 2.0961304,...</td>\n",
       "      <td>[[2.1478271, 1.4641495, -0.3640442, 0.5910034,...</td>\n",
       "      <td>[[1.6300049, 1.5985355, -0.1282959, 1.0488892,...</td>\n",
       "      <td>[[1.9754639, 1.1296768, -0.6564026, 0.30181885...</td>\n",
       "      <td>[[resemble, resembling], [neural, neuron], [le...</td>\n",
       "      <td>[[environment, environment], [learning, traini...</td>\n",
       "      <td>0.788166</td>\n",
       "      <td>0.735229</td>\n",
       "      <td>0.322950</td>\n",
       "      <td>0.220386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Give a definition for the term \"artificial ne...</td>\n",
       "      <td>Artificial Neural Networks are large parallel ...</td>\n",
       "      <td>2</td>\n",
       "      <td>artificial neural network large parallel proce...</td>\n",
       "      <td>A neural network is a massively parallel distr...</td>\n",
       "      <td>give definition term artificial neural network...</td>\n",
       "      <td>neural network massively parallel distributed ...</td>\n",
       "      <td>large parallel processing unit natural ability...</td>\n",
       "      <td>massively parallel distributed processor made ...</td>\n",
       "      <td>0.286963</td>\n",
       "      <td>[[1.5640869, 1.7378178, -0.1736145, 2.0961304,...</td>\n",
       "      <td>[[0.8804833984375, 1.3045060729980469, -0.4420...</td>\n",
       "      <td>[[1.6300049, 1.5985355, -0.1282959, 1.0488892,...</td>\n",
       "      <td>[[0.687978515625, 0.7240617370605469, -0.85735...</td>\n",
       "      <td>[[knowledge, knowledge], [processing, processi...</td>\n",
       "      <td>[[knowledge, knowledge], [processing, processi...</td>\n",
       "      <td>0.894408</td>\n",
       "      <td>0.828665</td>\n",
       "      <td>0.585639</td>\n",
       "      <td>0.482094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0   Give a definition for the term \"artificial ne...   \n",
       "1   Give a definition for the term \"artificial ne...   \n",
       "2   Give a definition for the term \"artificial ne...   \n",
       "3   Give a definition for the term \"artificial ne...   \n",
       "4   Give a definition for the term \"artificial ne...   \n",
       "\n",
       "                                      student_answer  grades_round  \\\n",
       "0  An artificial neural network is a massively pa...             2   \n",
       "1  Artificial neural network consists of: . Large...             2   \n",
       "2  An artificial neural network is a massive dist...             1   \n",
       "3  An ANN is a layered graphical model containing...             2   \n",
       "4  Artificial Neural Networks are large parallel ...             2   \n",
       "\n",
       "                                    student_modified  \\\n",
       "0  artificial neural network massively parallel d...   \n",
       "1  artificial neural network consists largely par...   \n",
       "2  artificial neural network massive distributed ...   \n",
       "3  ann layered graphical model containing neuron ...   \n",
       "4  artificial neural network large parallel proce...   \n",
       "\n",
       "                                          ref_answer  \\\n",
       "0  A neural network is a massively parallel distr...   \n",
       "1  A neural network is a massively parallel distr...   \n",
       "2  A neural network is a massively parallel distr...   \n",
       "3  A neural network is a massively parallel distr...   \n",
       "4  A neural network is a massively parallel distr...   \n",
       "\n",
       "                                         qn_modified  \\\n",
       "0  give definition term artificial neural network...   \n",
       "1  give definition term artificial neural network...   \n",
       "2  give definition term artificial neural network...   \n",
       "3  give definition term artificial neural network...   \n",
       "4  give definition term artificial neural network...   \n",
       "\n",
       "                                        ref_modified  \\\n",
       "0  neural network massively parallel distributed ...   \n",
       "1  neural network massively parallel distributed ...   \n",
       "2  neural network massively parallel distributed ...   \n",
       "3  neural network massively parallel distributed ...   \n",
       "4  neural network massively parallel distributed ...   \n",
       "\n",
       "                                     student_demoted  \\\n",
       "0  massively parallel distributed processor simpl...   \n",
       "1  consists largely parallel distributed processo...   \n",
       "2  massive distributed processor consists several...   \n",
       "3  ann layered graphical model containing neuron ...   \n",
       "4  large parallel processing unit natural ability...   \n",
       "\n",
       "                                         ref_demoted  length_ratio  \\\n",
       "0  massively parallel distributed processor made ...      0.251889   \n",
       "1  massively parallel distributed processor made ...      0.232759   \n",
       "2  massively parallel distributed processor made ...      0.102828   \n",
       "3  massively parallel distributed processor made ...      0.327616   \n",
       "4  massively parallel distributed processor made ...      0.286963   \n",
       "\n",
       "                                           embed_ref  \\\n",
       "0  [[1.5640869, 1.7378178, -0.1736145, 2.0961304,...   \n",
       "1  [[1.5640869, 1.7378178, -0.1736145, 2.0961304,...   \n",
       "2  [[1.5640869, 1.7378178, -0.1736145, 2.0961304,...   \n",
       "3  [[1.5640869, 1.7378178, -0.1736145, 2.0961304,...   \n",
       "4  [[1.5640869, 1.7378178, -0.1736145, 2.0961304,...   \n",
       "\n",
       "                                          embed_stud  \\\n",
       "0  [[2.2006836, 0.86382484, 0.27182007, 2.5562744...   \n",
       "1  [[1.335439453125, 1.0990445709228516, 0.529989...   \n",
       "2  [[0.41577148, -0.37836266, 0.22351074, 0.95300...   \n",
       "3  [[2.1478271, 1.4641495, -0.3640442, 0.5910034,...   \n",
       "4  [[0.8804833984375, 1.3045060729980469, -0.4420...   \n",
       "\n",
       "                                   embed_ref_demoted  \\\n",
       "0  [[1.6300049, 1.5985355, -0.1282959, 1.0488892,...   \n",
       "1  [[1.6300049, 1.5985355, -0.1282959, 1.0488892,...   \n",
       "2  [[1.6300049, 1.5985355, -0.1282959, 1.0488892,...   \n",
       "3  [[1.6300049, 1.5985355, -0.1282959, 1.0488892,...   \n",
       "4  [[1.6300049, 1.5985355, -0.1282959, 1.0488892,...   \n",
       "\n",
       "                                  embed_stud_demoted  \\\n",
       "0  [[2.0412598, 0.49321938, 0.10058594, 1.2648926...   \n",
       "1  [[1.1956689453125, 0.7539517974853516, 0.13561...   \n",
       "2  [[0.38427734, -0.48944664, 0.17224121, 0.55065...   \n",
       "3  [[1.9754639, 1.1296768, -0.6564026, 0.30181885...   \n",
       "4  [[0.687978515625, 0.7240617370605469, -0.85735...   \n",
       "\n",
       "                                             aligned  \\\n",
       "0  [[neural, neural], [network, network], [massiv...   \n",
       "1  [[knowledge, knowledge], [parallel, parallel],...   \n",
       "2  [[knowledge, knowledge], [neural, neural], [ne...   \n",
       "3  [[resemble, resembling], [neural, neuron], [le...   \n",
       "4  [[knowledge, knowledge], [processing, processi...   \n",
       "\n",
       "                                     aligned_demoted  cos_similarity  \\\n",
       "0  [[simple, simple], [processing, processing], [...        0.947867   \n",
       "1  [[knowledge, knowledge], [knowledge, knowledge...        0.964398   \n",
       "2  [[knowledge, knowledge], [distributed, distrib...        0.854767   \n",
       "3  [[environment, environment], [learning, traini...        0.788166   \n",
       "4  [[knowledge, knowledge], [processing, processi...        0.894408   \n",
       "\n",
       "   cos_similarity_demo  aligned_score  aligned_score_demo  \n",
       "0             0.933466       0.969697            0.950888  \n",
       "1             0.951182       0.883259            0.818713  \n",
       "2             0.775333       0.498039            0.465632  \n",
       "3             0.735229       0.322950            0.220386  \n",
       "4             0.828665       0.585639            0.482094  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print (np.sum(df['cos_similarity']<0))\n",
    "print (np.sum(df['cos_similarity'].isnull()))\n",
    "# print (np.sum(df['cos_similarity_demo']<0))\n",
    "# print (np.sum(df['cos_similarity_demo'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question_id', 'question', 'ref_answer', 'student_answer', 'grade',\n",
       "       'qn_modified', 'ref_modified', 'student_modified', 'student_demoted',\n",
       "       'ref_demoted', 'length_ratio', 'grades_round', 'embed_ref',\n",
       "       'embed_stud', 'aligned', 'aligned_demoted', 'embed_ref_demoted',\n",
       "       'embed_stud_demoted', 'cos_similarity', 'cos_similarity_demo',\n",
       "       'aligned_score', 'aligned_score_demo', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_pickle(\"../../dataset/final_dataset/mohler_final.pkl\")\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'question_id', 'ref_answer', 'student_answer',\n",
       "       'result', 'grades_round', 'student_modified', 'qn_modified',\n",
       "       'ref_modified', 'student_demoted', 'ref_demoted', 'length_ratio',\n",
       "       'embed_ref', 'embed_stud', 'embed_ref_demoted', 'embed_stud_demoted',\n",
       "       'aligned', 'aligned_demoted', 'cos_similarity', 'cos_similarity_demo',\n",
       "       'aligned_score', 'aligned_score_demo', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../../dataset/final_dataset/sem_eval_train.pkl\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"ques_id\":\"question_id\",\"reference_answer\":\"ref_answer\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../../dataset/final_dataset/sem_eval_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlgeval",
   "language": "python",
   "name": "maluuba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
