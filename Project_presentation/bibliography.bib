% This file was created with JabRef 2.10.
% Encoding: UTF-8

@book{Burrows2015,
abstract = {Abstract Automatic short answer grading (ASAG) is the task of assessing short nat- ural language responses to objective questions using computational methods. The active research in this field has increased enormously of late with over 80 papers fit- ting a definition of ASAG. However, the past efforts have generally been ad-hoc and non-comparable until recently, hence the need for a unified view of the whole field. The goal of this paper is to address this aim with a comprehensive review of ASAG research and systems according to history and components. Our historical analysis identifies 35 ASAG systems within 5 temporal themes that mark advancement in methodology or evaluation. In contrast, our component analysis reviews 6 common dimensions from preprocessing to effectiveness. A key conclusion is that an era of evaluation is the newest trend in ASAG research, which is paving the way for the consolidation of the field.},
author = {Burrows, Steven and Gurevych, Iryna and Stein, Benno},
booktitle = {International Journal of Artificial Intelligence in Education},
doi = {10.1007/s40593-014-0026-8},
file = {:home/black-book/HBRS/II/RnD/NLP Papers/The Eras and Trends of Automatic Short Answer Grading.pdf:pdf},
isbn = {4059301400268},
issn = {15604306},
keywords = {Automatic grading,Natural language processing,Short answer},
number = {1},
pages = {60--117},
title = {{The eras and trends of automatic short answer grading}},
volume = {25},
year = {2015}
}
@inproceedings{dligach2011,
  title={Good seed makes a good crop: accelerating active learning using language modeling},
  author={Dligach, Dmitriy and Palmer, Martha},
  booktitle={Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2},
  pages={6--10},
  year={2011},
  organization={Association for Computational Linguistics}
}
@article{figueroa2012,
  title={Active learning for clinical text classification: is it better than random sampling?},
  author={Figueroa, Rosa L and Zeng-Treitler, Qing and Ngo, Long H and Goryachev, Sergey and Wiechmann, Eduardo P},
  journal={Journal of the American Medical Informatics Association},
  volume={19},
  number={5},
  pages={809--816},
  year={2012},
  publisher={BMJ Group BMA House, Tavistock Square, London, WC1H 9JR}
}
@article{Settles2010,
abstract = {The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns. An active learner may pose queries, usually in the form of unlabeled data instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant or easily obtained, but labels are difficult, time-consuming, or expensive to obtain. This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for successful active learning, a summary of problem setting variants and practical issues, and a discussion of related topics in machine learning research are also presented.},
archivePrefix = {arXiv},
arxivId = {1206.5533},
author = {Settles, Burr},
doi = {10.1.1.167.4245},
eprint = {1206.5533},
file = {:home/black-book/HBRS/II/RnD/NLP Papers/Active Learning Literature Survey.pdf:pdf},
isbn = {978-1-4673-8391-2},
issn = {00483931},
journal = {Machine Learning},
number = {2},
pages = {201--221},
pmid = {15003161},
title = {{Active Learning Literature Survey}},
volume = {15},
year = {2010}
}
@article{Mohler2011,
author = {Mohler, M. and Bunescu, R. and Mihalcea, R.},
file = {:home/black-book/HBRS/II/RnD/NLP Papers/Learning to Grade Short Answer Questions using Semantic Similarity
Measures and Dependency Graph Alignments - Mohler.pdf:pdf},
pages = {752--762},
title = {{Learning to grade short answer questions using semantic similarity measures and dependency graph alignments}},
year = {2011}
}
@techreport{dzikovska2013,
  title={Semeval-2013 task 7: The joint student response analysis and 8th recognizing textual entailment challenge},
  author={Dzikovska, Myroslava O and Nielsen, Rodney D and Brew, Chris and Leacock, Claudia and Giampiccolo, Danilo and Bentivogli, Luisa and Clark, Peter and Dagan, Ido and Dang, Hoa T},
  year={2013},
  institution={NORTH TEXAS STATE UNIV DENTON}
}
@unpublished{ramesh2,
	Authors = {Ramesh Kumar},
	Month = {January},
	Note = {WS17
	H-BRS - Evaluation of Semantic Textual Similarity Approaches for Automatic Short Answer Grading Ploeger, Nair supervising},
	Title = {Evaluation of Semantic Textual Similarity Approaches for Automatic Short Answer Grading},
	Year = {2017/18}
}
@article{Sultan2016,
abstract = {We present a fast, simple, and high-accuracy short answer grading system. Given a short-answer question and its correct answer, key measures of the correctness of a student re-sponse can be derived from its semantic sim-ilarity with the correct answer. Our super-vised model (1) utilizes recent advances in the identification of short-text similarity, and (2) augments text similarity features with key grading-specific constructs. We present exper-imental results where our model demonstrates top performance on multiple benchmarks.},
author = {Sultan, Md Arafat and Salazar, Cristobal and Sumner, Tamara},
doi = {10.18653/v1/N16-1123},
file = {:home/black-book/HBRS/II/RnD/NLP Papers/Fast and Easy Short Answer Grading with High Accuracy.pdf:pdf},
isbn = {9781941643914},
journal = {Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
pages = {1070--1075},
title = {{Fast and Easy Short Answer Grading with High Accuracy}},
year = {2016}
}
@misc{tf_idf_defi,
  title = {tf-idf},
  howpublished = {\url{https://en.wikipedia.org/wiki/Tf-idf}},
  note = {Accessed: 2018-11-22}
}
